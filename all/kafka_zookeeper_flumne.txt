一、kafka
    1、 Kafka集群Leader均衡(Balancing leadership)
        1.1、手动
            kafka-preferred-replica-election.sh --zookeeper www.iteblog.com:2181
        2.2、自动平衡
            server.properties 中配置:
            auto.leader.rebalance.enable=true


    2、kafka 如何保证数据有序? 如何保证数据不丢失?有多少个 partition?


二、kafka 基本操作
    1、创建 topic
         kafka-topics --create --zookeeper mphd02:2181,mphd03:2181,mphd04:2181 --replication-factor 3 --partitions 1 --topic fisrtopic
    2、查看 指定 topic 的详细信息
        kafka-topics --describe --zookeeper mphd02:2181,mphd03:2181,mphd04:2181 --topic fisrtopic
    3、查看 集群上的所有topic
        kafka-topics --list --zookeeper mphd02:2181,mphd03:2181,mphd04:2181
    4、修改topic
        不能修改replication-factor，以及只能对partition个数进行增加，不能减少
        kafka-topics --alter --zookeeper mphd02:2181,mphd03:2181,mphd04:2181 --partitions 2 --topic fisrtopic
    5、删除 topic
        kafka-topics --delete --zookeeper mphd02:2181,mphd03:2181,mphd04:2181 --topic fisrtopic
        彻底删除一个topic，需要在server.properties中配置delete.topic.enable=true，否则只是标记删除
    6、生产数据
        kafka-console-producer --broker-list mphd07:9092,mphd08:9092,mphd09:9092 --topic fisrtopic1
       生产数据的时候需要指定：当前数据流向哪个broker，以及哪一个topic
    7、消费者
        kafka-console-consumer --zookeeper mphd02:2181,mphd03:2181,mphd04:2181 --topic fisrtopic1 --from-beginning
        说明：该消费语句，只能获取最新的数据，要想历史数据，需要添加选项--from-beginning
                   在消费数据的时候，只需要指定topic，以及topic的元数据信息即可(在ZK中存放)，所以这里需要使用zk

    8、黑名单和白名单
        消费者--黑名单(blacklist)和白名单(whitelist)选项
            --blacklist 后面跟需要过滤的topic的列表，使用","隔开，意思是除了列表中的topic之外，都能接收其它topic的数据
            --whitelist 后面跟需要过滤的topic的列表，使用","隔开，意思是除了列表中的topic之外，都不能接收其它topic的数据
        kafka-console-consumer --zookeeper mphd02:2181,mphd03:2181,mphd04:2181 --from-beginning --whitelist fisrt_opic,fisrt_opic1
        kafka-console-consumer --zookeeper mphd02:2181,mphd03:2181,mphd04:2181 --from-beginning --blacklist fisrtopic1,my_topic

        kafka-topics --create --zookeeper mphd02:2181,mphd03:2181,mphd04:2181 --replication-factor 3 --partitions 1 --topic test
        kafka-topics --describe --zookeeper mphd02:2181,mphd03:2181,mphd04:2181 --topic test

        kafka-console-producer --broker-list mphd07:9092,mphd08:9092,mphd09:9092 --topic test



三、kafka 中 zokeeper 作用
    1、
        1、kafaka集群的 broker，和 Consumer 都需要连接 Zookeeper。Producer 直接连接 Broker。
        2、Producer 把数据上传到 Broker，Producer可以指定数据有几个分区、几个备份。黄色的分区为 leader，白色的为 follower
        3、leader 处理 partition 的所有读写请求，与此同时，follower会被动定期地去复制leader上的数据。 如下图所示，红色的为 leader，绿色的为 follower，leader复制自己到其他 Broker 中：
        4、如果leader发生故障或挂掉，一个新leader被选举并接收客户端的消息。Kafka确保从同步副本列表中选举一个副本为 leader。
        5、Topic 分区被放在不同的 Broker 中，保证 Producer 和 Consumer 错开访问 Broker，避免访问单个 Broker造成过度的IO压力，使得负载均衡。
    2、作用
        1、Broker注册
            Broker是分布式部署并且相互之间相互独立，但是需要有一个注册系统能够将整个集群中的Broker管理起来，此时就使用到了Zookeeper。
            在Zookeeper上会有一个专门用来进行Broker服务器列表记录的节点 /brokers/ids  每个Broker在启动时，都会到Zookeeper上进行注册。
            Broker创建的节点类型是临时节点，一旦Broker宕机，则对应的临时节点也会被自动删除。
        2、Topic注册
            在Kafka中，同一个Topic的消息会被分成多个分区并将其分布在多个Broker上，这些分区信息及与Broker的对应关系也都是由Zookeeper在维护，
            由专门的节点来记录, /borkers/topics;
            /brokers/topics/login/3->2，这个节点表示Broker ID为3的一个Broker服务器，对于"login"这个Topic的消息，提供了2个分区进行消息存储，同样，这个分区节点也是临时节点。

        3、生产者负载均衡
            使用Zookeeper进行负载均衡，由于每个Broker启动时，都会完成Broker注册过程，生产者会通过该节点的变化来动态地感知到Broker服务器列表的变更，这样就可以实现动态的负载均衡机制

        4、消息 消费进度Offset 记录

        5、消费者注册

四、kafka 分组 与 分区
    1、你可以把分区当成队列，5个分区=5个队列，10条消息平均存储在5个队列中，组A里的5个消费者=5个队列。如果组里有6个消费者，那么就将有1个消费者永远拿不到消息。
    2、一个topic有5个分区，里面有10条消息，这些消息以组为单位，发给每个组，比如其中一个组A里有5个消费者，那么5个消费者将平分这些消息。组B也会同样收到10条消息，组B内的消费者平分这10条。

    3、分组 与 分区的 计算 公式
        其实kafka的消费端有一个均衡算法，算法如下：
        1.A=(partition数量/同分组消费者总个数)
        2.M=对上面所得到的A值小数点第一位向上取整
        3.计算出该消费者拉取数据的 patition 合集：Ci = [P(M*i ),P((i + 1) * M -1)]
            A=6/8=0.75
            M=1
            C0=[P(1*0),P((0+1)*1-1)]=[P0,P0]
            同理：
            C1=[P(1*1),P((1+1)*1-1)]=[P1,P1]
            C2=[P(1*2),P((2+1)*1-1)]=[P2,P2]

          如果这个消费组里面的消费者少于partition数量呢（比如5个）
          即 只有 5个消费者 6 个分组呢
            A=6/5=1.2 
            M=2
            C0=[P(2*0),P((0+1)*2-1)]=[P0,P1]
            C1=[P(2*1),P((1+1)*2-1)]=[P2,P3] 
            C2=[P(2*2),P((2+1)*2-1)]=[P4,P5]

            C3=[P(2*3),P((3+1)*2-1)]=[P6,P7] 
            C4=[P(2*4),P((4+1)*2-1)]=[P8,P9]

            c3 和 c4  不起作用,不会消费任何东西
    4、分组 和分区 的关系
        总结：
        1.按照如上的算法，所以如果kafka的消费组需要增加组员，最多增加到和partition数量一致，超过的组员只会占用资源，而不起作用；
        2.kafka的partition的个数一定要大于消费组组员的个数，并且partition的个数对于 消费组组员 取模 一定要为 0 ，
            不然有些消费者会占用资源却不起作用；

        3.如果需要增加消费组的组员个数，那么也需要根据上面的算法，调整partition的个数


    ISR机制：
        1. leader会维护一个与其基本保持同步的Replica列表，该列表称为ISR(in-sync Replica)，每个Partition都会有一个ISR，而且是由leader动态维护
        2. 如果一个flower比一个leader落后太多，或者超过一定时间未发起数据复制请求，则leader将其重ISR中移除
        3. 当ISR中所有Replica都向Leader发送ACK时，leader才commit
        既然所有Replica都向Leader发送ACK时，leader才commit，那么flower怎么会leader落后太多？
        producer往kafka中发送数据，不仅可以一次发送一条数据，还可以发送message的数组；批量发送，同步的时候批量发送，异步的时候本身就是就是批量；底层会有队列缓存起来，批量发送，对应broker而言，就会收到很多数据(假设1000)，这时候leader发现自己有1000条数据，flower只有500条数据，落后了500条数据，就把它从ISR中移除出去，这时候发现其他的flower与他的差距都很小，就等待；如果因为内存等原因，差距很大，就把它从ISR中移除出去。
        4、对于每个Partition而言，每个Broker上最多只会有一个Replica，因此可以使用Broker id 指定Partition的Replica。


    server配置
        rerplica.lag.time.max.ms=10000  rerplica 等待时间  默认10s 就从 ISR 中移除
        rerplica.lag.max.messages=4000 # 相差4000条就从 ISR 中移除
        # flower慢的时候，保证高可用性，同时满足这两个条件后又加入ISR中，
        # 在可用性与一致性做了动态平衡   亮点

    topic配置
        min.insync.replicas=1 # 需要保证ISR中至少有多少个replica

    Producer配置
      request.required.asks=0
      # 0:相当于异步的，不需要leader给予回复，producer立即返回，发送就是成功, 那么发送消息网络超时或broker crash(1.Partition的Leader还没有commit消息 2.Leader与Follower数据不同步)，既有可能丢失也可能会重发
      # 1：当leader接收到消息之后发送ack，丢会重发，丢的概率很小
      # -1：当所有的follower都同步消息成功后发送ack.  丢失消息可能性比较低


    5、Data Replication 如何处理Replica全部宕机
        1、等待ISR中任一 Replica 恢复,并选它为Leader
        等待时间较长,降低可用性， 或ISR中的所有Replica都无法恢复或者数据丢失,则该Partition将永不可用

        2、选择第一个恢复的Replica为新的Leader,无论它是否在ISR中
        并未包含所有已被之前Leader Commit过的消息,因此会造成数据丢失， 可用性较高

    6、Zookeeper 的分布式锁




六、kafka 再分配机制
    1、修改 分区数
        ./bin/kafka-topics.sh --zookeeper vlnx111122:2181 --alter --topic test --partitions 6
    2、消息数据迁移:
        kafka-reassign-partitions.sh
        这个脚本提供3个命令：
            --generate: 根据给予的Topic列表和Broker列表生成迁移计划。generate并不会真正进行消息迁移，而是将消息迁移计划计算出来，供execute命令使用。
            --execute: 根据给予的消息迁移计划进行迁移。
            --verify: 检查消息是否已经迁移完成。

          topic.json: {"topics": [{"topic": "test"} ], "version": 1}
        1、./bin/kafka-reassign-partitions.sh --zookeeper vlnx111122:2181 --topics-to-move-json-file topic.json --broker-list "1,2,3,4,5" --generate
        2、./bin/kafka-reassign-partitions.sh --zookeeper vlnx111122:2181 --reassignment-json-file reassignment.json --execute
        3、./bin/kafka-reassign-partitions.sh --zookeeper vlnx111122:2181 --reassignment-json-file reassignment.json --verify


七、0.8 和0.9 的区别
    1、引入新的Consumer API
        1.1、kafka0.8.0 的 consumer客户端需要不断与kafka集群的zookeeper交互，以获取最新的offset。
            而新的consumer的offset则是交给kafka来管理，kafka通过创建专用的topic进行管理不同partition的offset。kafka自己维护了partition的offset，以供同一个partition的不同consumer使用
        1.2、Consumer可以订阅特殊的partition，实现指定消费partition的功能
        1.3、在kafka外部存储offset
            允许在kafka外部存储offset，也就是consumer和kafka同时维护一个offset，消费者程序不一定要使用kafka内置的offset存储，而是可以自主选择offset的存储方式。如果能够实现offset和result的原子性保存，将会实现exactly once的事务性保证

    2、引入了安全管理机制
        客户端（producer和consumer）连接broker时，可以使用SSL或者SASL进行验证。
        验证从broker到zookeeper的连接

    3、引入了Kafka Connect：
        kafka connect是一个支持Scala的可靠工具。使用它来定义一个数据导入与导出的connector很容易。具有时延低，API操作简单的特征，支持分布式或单机模式


八、kafka 的 controler 组件的作用
    1、Kafka集群中的其中一个Broker会被选举为Controller，主要负责Partition管理和副本状态管理，
        也会执行类似于重分配Partition之类的管理任务。
        如果当前的Controller失败，会从其他正常的Broker中重新选举Controller。

    2、ReplicaManager：负责管理当前broker所有分区和副本的信息，会处理 KafkaController 发起的一些请求，副本状态的切换，添加/读取消息等


九、kafka 目录
    一 Kafka在zookeeper注册的一些节点路径
    /brokers/ids/[id] 记录集群中的broker id
    /brokers/topics/[topic]/partitions 记录了topic所有分区分配信息以及AR集合
    /brokers/topics/[topic]/partitions/[partition_id]/state记录了某partition的leader副本所在brokerId,leader_epoch, ISR集合,zk 版本信息

十、kafka 是落盘的框架， 吞吐量为什么大
    1、生产者（写入数据）
        顺序写入和MMFile。 缺陷——没有办法删除数据，所以Kafka是不会删除数据的
        所以Kafka的数据并不是实时的写入硬盘，它充分利用了现代操作系统分页存储来利用内存提高I/O效率
        Memory Mapped Files(后面简称mmap)也被翻译成内存映射文件，
        它的工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上（操作系统在适当的时候）
        它把所有的消息都变成一个的文件。通过mmap提高I/O速度，写入数据的时候它是末尾添加所以速度最优

    2、消费者（读取数据）
        Kafka把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候Kafka直接把“文件”发送给消费者。
        Kafka是用mmap作为文件读写方式的，它就是一个文件句柄，所以直接把它传给sendfile


    1.kafka集群的规模，消费速度是多少。
        答：一般中小型公司是10个节点，每秒20M左右。









十一、 flume 总结
    7.1 你是如何实现Flume数据传输的监控的
        使用第三方框架 Ganglia 实时监控Flume。

    7.2 Flume的Source，Sink，Channel的作用？你们Source是什么类型？
        （1）Source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy
        （2）Channel组件对采集到的数据进行缓存，可以存放在Memory或File中。
        （3）Sink组件是用于把数据发送到目的地的组件，目的地包括 Hdfs、Logger、avro、thrift、ipc、file、Hbase、solr、自定义。

        2、我公司采用的Source类型为：

        （1）监控后台日志：exec
        （2）监控后台产生日志的端口：netcat
        （3）传输日志文件: spooldir


    7.3 Flume的 Channel Selectors
        channel seletors 可以让不同的项目日志通过不同的chanel到不痛的sink中去， selectorsyou两种， replicating channel selectors（default） 和 multiplexing channel selector
        replicating 会将source 过来的 events 发往所有的 channel，而 multiplexing 可以选择该发往那些 chanel

    7.4 Flume参数调优
        Source
            1、增加Source个（使用Tair Dir Source时可增加FileGroups个数）可以增大Source的读取数据的能力。例如：当某一个目录产生的文件过多时需要将这个文件目录拆分成多个文件目录，同时配置好多个Source 以保证Source有足够的能力获取到新产生的数据。
            2、batchSize 参数决定Source一次批量运输到Channel的event条数，适当调大这个参数可以提高Source搬运Event到Channel时的性能。

        Channel
            1、type 选择memory时Channel的性能最好，但是如果Flume进程意外挂掉可能会丢失数据。type选择file时Channel的容错性更好，但是性能上会比memory channel差。
            使用file Channel时dataDirs配置多个不同盘下的目录可以提高性能。

            2、Capacity 参数决定Channel可容纳最大的event条数。
            3、transactionCapacity 参数决定每次Source往channel里面写的最大event条数和每次Sink从channel里面读的最大event条数。transactionCapacity需要大于Source和Sink的batchSize参数。

        Sink
            1、增加Sink的个数可以增加Sink消费event的能力。Sink也不是越多越好够用就行，过多的Sink会占用系统资源，造成系统资源不必要的浪费。
            2、batchSize参数决定Sink一次批量从Channel读取的event条数，适当调大这个参数可以提高Sink从Channel搬出event的性能。

    7.5 Flume的事务机制
        Flume的事务机制（类似数据库的事务机制）：Flume使用两个独立的事务分别负责从Soucrce到Channel，以及从Channel到Sink的事件传递。
        比如spooling directory source 为文件的每一行创建一个事件，一旦事务中所有的事件全部传递到Channel且提交成功，那么Soucrce就将该文件标记为完成。
        同理，事务以类似的方式处理从Channel到Sink的传递过程，如果因为某种原因使得事件无法记录，那么事务将会回滚。且所有的事件都会保持到Channel中，等待重新传递。

    7.6 Flume采集数据会丢失吗?
        不会，Channel存储可以存储在File中，数据传输自身有事务




十二、 zookeeper 是hadoop的分布式协调服务
    1、zookeeper的选举机制
        刚开始启动：
            假设有五台服务器组成的zookeeper集群,它们的id从1-5,同时它们都是最新启动的,也就是没有历史数据,在存放数据量这一点上,都是一样的.假设这些服务器依序启动,来看看会发生什么.
            1) 服务器1启动,此时只有它一台服务器启动了,它发出去的报没有任何响应,所以它的选举状态一直是LOOKING状态
            2) 服务器2启动,它与最开始启动的服务器1进行通信,互相交换自己的选举结果,由于两者都没有历史数据,所以id值较大的服务器2胜出,但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是3),所以服务器1,2还是继续保持LOOKING状态.
            3) 服务器3启动,根据前面的理论分析,服务器3成为服务器1,2,3中的老大,而与上面不同的是,此时有三台服务器选举了它,所以它成为了这次选举的leader.
            4) 服务器4启动,根据前面的分析,理论上服务器4应该是服务器1,2,3,4中最大的,但是由于前面已经有半数以上的服务器选举了服务器3,所以它只能接收当小弟的命了.
            5) 服务器5启动,同4一样,当小弟.
        当有服务器down掉的时候:
            逻辑时钟:这个值从0开始递增,每次选举对应一个值
            数据id：数据新的id就大，数据每次更新都会更新id。
            Leader id：就是我们配置的myid中的值，每个机器一个。
            选举的标准就变成：
            1、逻辑时钟小的选举结果被忽略，重新投票
            2、统一逻辑时钟后，数据id大的胜出
            3、数据id相同的情况下，leader id大的胜出

    2、Server服务器的三种状态：
        Looking:当前server不知道谁是leader，正在搜寻
        Leader：当前server即为选举出来的leader
        Follower：leader已经选举出来，当前server与之同步

    3、主从分工：
        Leader：负责投票的发起和决议，更新系统的状态
        Learner：
            follower: 勇于接受客户端请求，并向客户返回结果，在选举过程中，参与投票
            observer: 可以接受客户端链接，将写的请求转发给leader，但是observer不参加投票过程，只同步leader状态，observer的目的是为了扩展系统，提高读取速度。


    4、Zookeeper 对外提供服务的三个作用：
        作用: 分布式应用程序可以基于 ZooKeeper 实现诸如数据 发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。
        注册
        事件监控
        回调


    5、zk的基本特性：
        (1) 可靠存储小量数据且提供强一致性
        (2) ephemeral node, 在创建它的客户端关闭后，可以自动删除
        (3) 对于node状态的变化，可以提供异步的通知(watcher)


    6、一、分布式锁介绍
        分布式锁主要用于在分布式环境中保护跨进程、跨主机、跨网络的共享资源实现互斥访问，以达到保证数据的一致性。
        持久节点:
        临时顺序节点:
        6.1、分布式锁获取思路
            1、在zookeeper指定节点（locks）下创建临时顺序节点node_n
            2、获取locks下所有子节点children
            3、对子节点按节点自增序号从小到大排序
            4、判断本节点是不是第一个子节点，若是，则获取锁；若不是，则监听比该节点小的那个节点的删除事件(zookeeper会通知客户端)
            5、若监听事件生效，则回到第二步重新进行判断，直到获取到锁

            6、事件监听: 当前zookeeper有如下四种事件：1）节点创建；2）节点删除；3）节点数据修改；4）子节点变更。